{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Football.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VJ_8kByf_4XouLk64jM9o_I-JEeqOtvk",
      "authorship_tag": "ABX9TyOOigDve+tGx728+bWXB5lP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyaBansal68/ML-Project-winter-2022/blob/main/Football_Logistic_Neural_XG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bQuEoMPizCwG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime as dt\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "#A random forest is a meta estimator that fits a number of decision tree classifiers\n",
        "#on various sub-samples of the dataset and use averaging to improve the predictive\n",
        "#accuracy and control over-fitting.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#a discriminative classifier formally defined by a separating hyperplane.\n",
        "from sklearn.svm import SVC\n",
        "#displayd data\n",
        "from IPython.display import display\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import log_loss,accuracy_score,roc_auc_score,f1_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Football/train.csv')"
      ],
      "metadata": {
        "id": "Xp-q42BzzeJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "W7fepgfw0_tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "bgtxIHz3zjVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns.tolist()"
      ],
      "metadata": {
        "id": "A2EhNXKd1CQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.drop(['match_date','home_team_history_match_date_1','league_name',\n",
        " 'home_team_history_match_date_2',\n",
        " 'home_team_history_match_date_3',\n",
        " 'home_team_history_match_date_4',\n",
        " 'home_team_history_match_date_5',\n",
        " 'home_team_history_match_date_6',\n",
        " 'home_team_history_match_date_7',\n",
        " 'home_team_history_match_date_8',\n",
        " 'home_team_history_match_date_9',\n",
        " 'home_team_history_match_date_10', \n",
        " 'away_team_history_match_date_1',\n",
        " 'away_team_history_match_date_2',\n",
        " 'away_team_history_match_date_3',\n",
        " 'away_team_history_match_date_4',\n",
        " 'away_team_history_match_date_5',\n",
        " 'away_team_history_match_date_6',\n",
        " 'away_team_history_match_date_7',\n",
        " 'away_team_history_match_date_8',\n",
        " 'away_team_history_match_date_9','away_team_history_match_date_10'], axis=1)"
      ],
      "metadata": {
        "id": "WMXVC9qP1XTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "fiDP3Yq715SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dNw66Y101EXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#win rate for the home team?\n",
        "\n",
        "# Total number of matches.\n",
        "n_matches = data.shape[0]\n",
        "\n",
        "# Calculate number of features. -1 because we are saving one as the target variable (win/lose/draw)\n",
        "n_features = data.shape[1] - 1\n",
        "\n",
        "# Calculate matches won by home team.\n",
        "n_homewins = len(data[data.target == 'home'])\n",
        "\n",
        "# Calculate win rate for home team.\n",
        "win_rate = (float(n_homewins) / (n_matches)) * 100\n",
        "\n",
        "# Print the results\n",
        "print (\"Total number of matches: {}\".format(n_matches))\n",
        "print (\"Number of features: {}\".format(n_features))\n",
        "print (\"Number of matches won by home team: {}\".format(n_homewins))\n",
        "print (\"Win rate of home team: {:.2f}%\".format(win_rate))"
      ],
      "metadata": {
        "id": "9NcVCLZy6Wkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "id": "rPeaYHQqFxs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.dropna()\n",
        "data"
      ],
      "metadata": {
        "id": "X61Y8HY3GQXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import category_encoders as ce\n",
        "# Shuffle and split the dataset into training and testing set.\n"
      ],
      "metadata": {
        "id": "gUJgA2Ow_dlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['target'] = data['target'].replace(['away','draw','home'],[0, 1, 2])"
      ],
      "metadata": {
        "id": "uTcXXj1OP5_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = ce.OrdinalEncoder(cols=['home_team_name' , 'away_team_name', 'is_cup'])\n",
        "data = encoder.fit_transform(data)"
      ],
      "metadata": {
        "id": "NXDf8sSejxSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "7zYaS0r0kkI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "rGLl5bSskLIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.barh(data.columns, rf.feature_importances_)\n",
        "#rf.feature_importances_\n"
      ],
      "metadata": {
        "id": "Vesaz5Ywk0lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_streak(data):\n",
        "    h_t_goal = \"home_team_history_goal_\"\n",
        "    h_t_opp_goal = \"home_team_history_opponent_goal_\"\n",
        "    a_t_goal = \"away_team_history_goal_\"\n",
        "    a_t_opp_goal = \"away_team_history_opponent_goal_\"\n",
        "    df[\"away_streak\"] = np.nan\n",
        "    df[\"home_streak\"] = np.nan\n",
        "    def apply_streaks(x):\n",
        "        home_streak = 0\n",
        "        away_streak = 0\n",
        "        home_streak_over = False\n",
        "        away_streak_over = False\n",
        "        \n",
        "        if  x[h_t_goal+str(1)] > x[h_t_opp_goal+str(1)]:\n",
        "            home_win_streak = True\n",
        "        else:\n",
        "            home_win_streak = False\n",
        "            \n",
        "        if  x[a_t_goal+str(1)] > x[a_t_opp_goal+str(1)]:\n",
        "            away_win_streak = True\n",
        "        else:\n",
        "            away_win_streak = False\n",
        "            \n",
        "        def check_streak(streak,streak_over,win_streak,team_goal,opp_goal):\n",
        "            if not streak_over and win_streak and team_goal > opp_goal:\n",
        "                streak+=1\n",
        "            elif not streak_over and not win_streak and team_goal < opp_goal:\n",
        "                streak-=1\n",
        "            elif not streak_over and team_goal == opp_goal:\n",
        "                pass\n",
        "            else:\n",
        "                streak_over = True\n",
        "            return streak, streak_over\n",
        "                \n",
        "        for i in range(1,11):\n",
        "            if not home_streak_over:\n",
        "                home_streak, home_streak_over = check_streak(home_streak,home_streak_over, home_win_streak, x[h_t_goal+str(i)],x[h_t_opp_goal+str(i)])\n",
        "            if not away_streak_over:\n",
        "                away_streak, away_streak_over = check_streak(away_streak,away_streak_over, away_win_streak, x[a_t_goal+str(i)],x[a_t_opp_goal+str(i)])\n",
        "            \n",
        "        return pd.Series([home_streak,away_streak],index=['home_streak','away_streak'])\n",
        "\n",
        "    \n",
        "    df[['home_streak','away_streak']] = df.apply(lambda x: apply_streaks(x), axis=1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "eL9_2qGUwiln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = add_streak(data)"
      ],
      "metadata": {
        "id": "oacurX5ayGIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data.columns:\n",
        "    if data[i].dtype == 'object':\n",
        "        data = data.drop([i],axis=1)\n",
        "        data = data.drop([i],axis=1)\n",
        "    if \"is_cup\" in i or \"history_is_play_home\" in i:\n",
        "        try:\n",
        "            data = data.drop([i],axis=1)\n",
        "            #X_test = X_test.drop([i],axis=1)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "for i in data.columns:\n",
        "    if 'rating' not in i and 'goal':\n",
        "        data[i] = data[i].fillna(-1)\n",
        "        #X_test[i] = X_test[i].fillna(-1)\n",
        "    else:\n",
        "        data[i] = data[i].fillna(data[i].mode())\n",
        "        #X_test[i] = X_test[i].fillna(X_train[i].mode())"
      ],
      "metadata": {
        "id": "Kiz4rlPpyVNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "RPEnejDJyug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['target'], axis = 1)\n",
        "y=data['target']"
      ],
      "metadata": {
        "id": "oy9-mJbQzEo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "I8Vc8I8VVJgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "nFQpr0bgTxZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "y_cat = to_categorical(y)"
      ],
      "metadata": {
        "id": "T5tYPmdcTclH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_scaled = pd.DataFrame(sc.fit_transform(X))"
      ],
      "metadata": {
        "id": "Xej0bcYAVAFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled\n"
      ],
      "metadata": {
        "id": "adBBVeRvVG1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat"
      ],
      "metadata": {
        "id": "MXJatPNxT0x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, \n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 42)"
      ],
      "metadata": {
        "id": "3R7v2LHTzJcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators=100)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "caCg2WACYylz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense,Softmax, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop\n",
        "\n",
        "modelN = Sequential()\n",
        "modelN.add(Dense(60, input_shape = (127,), activation = \"relu\"))\n",
        "modelN.add(Dense(15, activation = \"relu\"))\n",
        "modelN.add(Dropout(0.2))\n",
        "modelN.add(Dense(3, activation = \"softmax\"))\n",
        "modelN.compile(Adam(lr = 0.01), \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "modelN.summary()"
      ],
      "metadata": {
        "id": "z5FnXIcfVxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelN.fit(X_train, y_train, verbose=1, epochs=10)"
      ],
      "metadata": {
        "id": "JXLwQQS-Xswu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#y_pred_class = modelN.predict_classes(X_test)\n",
        "predict_x=modelN.predict(X_test) \n",
        "y_pred_class=np.argmax(predict_x,axis=1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = modelN.predict(X_test)\n",
        "y_test_class = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "6ZC2ElTYYRVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "confusion_matrix(y_test_class, y_pred_class)\n",
        "print(classification_report(y_test_class, y_pred_class))\n",
        "#print('Log loss score with  : {0:0.4f}'. format(log_loss(y_test_class,y_pred_class)))\n",
        "#print('Model accuracy score with : {0:0.4f}'. format(accuracy_score(y_test, predict_x)))\n",
        "#print('Model ROC with : {0:0.4f}'. format(roc_auc_score(y_test_class, y_pred_class,multi_class='ovr',average='weighted')))"
      ],
      "metadata": {
        "id": "b6aVaPuhZIo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_NN = Sequential([\n",
        "    layers.Input(127),\n",
        "    layers.Dense(60, activation = 'relu'),\n",
        "    layers.Dense(30,activation='relu'),\n",
        "    layers.Dense(10, activation = 'relu'),\n",
        "    layers.Dense(3)\n",
        "])"
      ],
      "metadata": {
        "id": "z25g8T0fwtAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_NN.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7hWftBoYQF9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_NN.summary()"
      ],
      "metadata": {
        "id": "Fr6o8HHNQI5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train1=pd.DataFrame(data=y_train)\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "zc4nTvBzRSKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_NN.fit(X_train, pd.DataFrame(data=y_train), batch_size=11000, epochs=500, verbose=1)"
      ],
      "metadata": {
        "id": "dg8Sg7vTQNBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "upJvG5KAQWwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "_q2G_r506N7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import log_loss,accuracy_score,roc_auc_score,f1_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "CBOmtCqPREYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_NN.predict(X_test)\n",
        "\n",
        "y_predN=np.argmax(predictions,axis=1)\n",
        "y_pred_accN = model_NN.predict(X_test)\n",
        "#y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(y_test.values)\n",
        "print(y_predN)\n",
        "\n"
      ],
      "metadata": {
        "id": "GkIzpKjWzq38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_X_train = scaler.fit_transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "NN_Predictions=model_NN.predict(scaled_X_test)\n",
        "#ypred = (NN_Predictions > 0.5).astype(int)\n",
        "\n",
        "ypred=np.argmax(NN_Predictions,axis=1)\n",
        "\n",
        "\n",
        "print('Log loss score with  : {0:0.4f}'. format(log_loss(y_test.values,ypred)))\n",
        "#print('Model accuracy score with : {0:0.4f}'. format(matthews_corrcoef(y_test,ypred)))\n",
        "print('Model roc score with : {0:0.4f}'. format(roc_auc_score(y_test,ypred,multi_class='ovr',average='weighted')))\n",
        "print('Model f1 score with : {0:0.4f}'. format(f1_score(y_test, ypred)))\n",
        "  "
      ],
      "metadata": {
        "id": "lLOJ-zqYRg1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "#from pandas import MultiIndex, Int64Index\n",
        "\n",
        "\n",
        "best_hyperparams = {'colsample_bytree': 0.9080289013373745, 'gamma': 1.2419885617337658, 'max_depth': 8.0, 'min_child_weight': 4.0, \n",
        "'n_estimators': 238.0, 'reg_alpha': 41.0, 'reg_lambda': 0.05050398016408508}\n",
        "\n",
        "rfc = XGBClassifier(n_estimators=int(best_hyperparams['n_estimators']), max_depth = int(best_hyperparams['max_depth']), \n",
        "gamma = best_hyperparams['gamma'],\n",
        "                    reg_alpha = int(best_hyperparams['reg_alpha']),min_child_weight=int(best_hyperparams['min_child_weight']),\n",
        "                    colsample_bytree=int(best_hyperparams['colsample_bytree']))\n",
        "rfc.fit(X_train, y_train)\n",
        "y_pred = rfc.predict_proba(X_test)\n",
        "y_pred_acc = rfc.predict(X_test)\n",
        "\n",
        "print(y_test.values)\n",
        "print(y_pred)\n",
        "print('Log loss score with  : {0:0.4f}'. format(log_loss(y_test.values,y_pred)))\n",
        "print('Model accuracy score with : {0:0.4f}'. format(accuracy_score(y_test, y_pred_acc)))\n",
        "print('Model ROC with : {0:0.4f}'. format(roc_auc_score(y_test.values, y_pred,multi_class='ovr',average='weighted')))"
      ],
      "metadata": {
        "id": "IcQtCFC40O25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_LR=Pipeline([('scaler', MinMaxScaler()), ('Logmodel', LogisticRegression(C=0.001,penalty='l2',solver='saga'))])\n",
        "#model_LR = LogisticRegression(C=0.001,penalty='l2',solver='saga')\n",
        "model_LR.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "CsizmcSq0oCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GGfjzGrf1SzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_acc1 = model_LR.predict(X_test)\n",
        "y_pred2 = model_LR.predict_proba(X_test)\n",
        "\n",
        "print('Log loss score with  : {0:0.4f}'. format(log_loss(y_test.values,predictions)))\n",
        "print('Model accuracy score with : {0:0.4f}'. format(accuracy_score(y_test, y_pred_acc1)))\n",
        "print('Model ROC with : {0:0.4f}'. format(roc_auc_score(y_test, y_pred2,multi_class=\"ovr\",average='weighted')))"
      ],
      "metadata": {
        "id": "4JXfQ9N10cIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vrk3KMi7cO_C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}